{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retraining MeTA classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we guide you through training a random forest model with our data and your labeled data, and then using that model to make predictions on your unlabeled data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#standard \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "\n",
    "#model to use\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "#model performance\n",
    "from sklearn.metrics import confusion_matrix, f1_score, precision_recall_fscore_support\n",
    "from sklearn.model_selection import cross_val_predict, cross_val_score, KFold, RandomizedSearchCV, train_test_split\n",
    "from scipy.stats import randint as sp_randint\n",
    "from time import time\n",
    "#for easy visualization of model performance\n",
    "import scikitplot as skplt\n",
    "\n",
    "#importing model\n",
    "import pickle \n",
    "\n",
    "#custom function for trim mean and std deviation\n",
    "def trim_mean_std(data, frac=0.05):    \n",
    "    mean = stats.trim_mean(data, frac)\n",
    "    std = stats.tstd(data, limits=(frac * np.max(data), (1 - frac) * np.max(data)))\n",
    "    return mean, std\n",
    "\n",
    "#Dictionary to convert amino acid abreviations\n",
    "aa_dict = {'ALA': 'A', 'CYS':'C', 'ASP': 'D', 'GLU':'E',\n",
    "          'PHE': 'F', 'GLY': 'G', 'HIS': 'H', 'ILE': 'I',\n",
    "          'LYS': 'K', 'LEU': 'L', 'MET': 'M', 'ASN': 'N',\n",
    "          'GLN': 'Q', 'ARG': 'R', 'SER': 'S', 'THR': 'T',\n",
    "          'VAL': 'V', 'TRP': 'W', 'TYR': 'Y'}\n",
    "\n",
    "#Dictionary to bucket amino acids\n",
    "condensed_dict = {'L': 'LAIVMH', 'A': 'LAIVMH', 'I': 'LAIVMH', 'V': 'LAIVMH', 'M': 'LAIVMH', 'H': 'LAIVMH',\n",
    "                  'D': 'DEQ', 'E': 'DEQ', 'Q': 'DEQ', \n",
    "                  'S': 'STGRFN', 'T': 'STGRFN', 'G': 'STGRFN', 'R': 'STGRFN', 'F': 'STGRFN', 'N': 'STGRFN',\n",
    "                  'K': 'K'}\n",
    "\n",
    "#important column headings\n",
    "nums = ['0%', '1%', '5%', '10%']\n",
    "ratio_cols = ['1/0', '5/0', '10/0', '5/1', '10/1', '10/5']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing data\n",
    "First, we import our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read our data\n",
    "IGPS = pd.read_csv('data/PTP1B_all.csv')\n",
    "PTP1B = pd.read_csv('data/IGPS_all.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save your labeled data set in the folder \"data.\" In the cell bellow, change the name of the string assigned to `labeled_data_filename` from `'sample_labeled.csv'` to your **labeled data set**. Structure the table identically to that in `'sample_labeled.csv'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0%</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>AA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>70817.0</td>\n",
       "      <td>48836.26190</td>\n",
       "      <td>35416.90963</td>\n",
       "      <td>13722.06797</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>56457.0</td>\n",
       "      <td>41255.86774</td>\n",
       "      <td>34030.53055</td>\n",
       "      <td>14549.18591</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>84293.0</td>\n",
       "      <td>70637.32580</td>\n",
       "      <td>51737.79568</td>\n",
       "      <td>24447.40255</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>37792.0</td>\n",
       "      <td>27637.72522</td>\n",
       "      <td>20032.70190</td>\n",
       "      <td>12014.13218</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>87872.0</td>\n",
       "      <td>68161.90034</td>\n",
       "      <td>47255.06422</td>\n",
       "      <td>34808.69365</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0%           1%           5%          10% AA\n",
       "0  70817.0  48836.26190  35416.90963  13722.06797  A\n",
       "1  56457.0  41255.86774  34030.53055  14549.18591  A\n",
       "2  84293.0  70637.32580  51737.79568  24447.40255  A\n",
       "3  37792.0  27637.72522  20032.70190  12014.13218  A\n",
       "4  87872.0  68161.90034  47255.06422  34808.69365  C"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INSERT YOUR LABELED DATA PATH HERE ####\n",
    "labeled_data_filename = 'data/sample_labeled.csv'\n",
    "labeled_data = pd.read_csv(labeled_data_filename).dropna(axis=0)\n",
    "labeled_data.columns = ['0%', '1%', '5%', '10%', 'AA'] \n",
    "labeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell bellow, change the name of the string assigned to `unlabeled_data_filename` from `'sample_unlabeled.csv'` to your **unlabeled data set**. Structure the table identically to that in `'sample_labeled.csv'`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0%</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>AA</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>44878.0</td>\n",
       "      <td>35399.39127</td>\n",
       "      <td>28197.90367</td>\n",
       "      <td>27808.87681</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>45768.0</td>\n",
       "      <td>31829.72942</td>\n",
       "      <td>14369.01023</td>\n",
       "      <td>18841.69090</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>80528.0</td>\n",
       "      <td>59971.64002</td>\n",
       "      <td>50153.13583</td>\n",
       "      <td>33555.46352</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>43642.0</td>\n",
       "      <td>36039.34709</td>\n",
       "      <td>27277.08781</td>\n",
       "      <td>27101.01449</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>98323.0</td>\n",
       "      <td>63613.22351</td>\n",
       "      <td>9940.21114</td>\n",
       "      <td>12906.80585</td>\n",
       "      <td>no_label</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0%           1%           5%          10%        AA\n",
       "0  44878.0  35399.39127  28197.90367  27808.87681  no_label\n",
       "1  45768.0  31829.72942  14369.01023  18841.69090  no_label\n",
       "2  80528.0  59971.64002  50153.13583  33555.46352  no_label\n",
       "3  43642.0  36039.34709  27277.08781  27101.01449  no_label\n",
       "4  98323.0  63613.22351   9940.21114  12906.80585  no_label"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### INSERT YOUR UNLABELED DATA PATH HERE ####\n",
    "unlabeled_data_filename = 'data/sample_unlabeled.csv'\n",
    "unlabeled_data = pd.read_csv(unlabeled_data_filename) \n",
    "unlabeled_data.columns = ['0%', '1%', '5%', '10%'] \n",
    "unlabeled_data['AA'] = ['no_label'] * unlabeled_data.shape[0]\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you loaded your data, all you should have to do is execute cells until you get your predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_protein = pd.concat((labeled_data, unlabeled_data) , axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_ratios(data):\n",
    "    ratio_cols = ['1/0', '5/0', '10/0', '5/1', '10/1', '10/5']\n",
    "    div_by_zero = data[['1%', '5%', '10%']].values / data[['0%']].values \n",
    "    div_by_one = data[['5%', '10%']].values / data[['1%']].values\n",
    "    div_by_five = data[['10%']].values / data[['5%']].values\n",
    "    ratios = np.concatenate((div_by_zero, div_by_one, div_by_five), axis=1)\n",
    "    ratios_df = pd.DataFrame(ratios, columns=ratio_cols)\n",
    "    return ratios_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#normal z score function\n",
    "def z_score(data):\n",
    "    means = np.mean(data, axis=0)\n",
    "    stds = np.std(data, axis=0)\n",
    "    zeroed_data = np.subtract(data, means)\n",
    "    scaled_data = np.divide(zeroed_data, stds)\n",
    "    return scaled_data \n",
    "\n",
    "#trim z score function\n",
    "def trim_log_z_score(data, frac=0.05):\n",
    "    '''\n",
    "    Args:\n",
    "    data (NUMPY ARRAY!!): numpy array of data to be log transformed and scaled, not robust to negative numbers\n",
    "    frac (float): how much to trim mean and standard deviation\n",
    "    Returns:\n",
    "    scaled_data (numpy array): log transformed and scaled data\n",
    "    '''\n",
    "    log_data = np.log(np.clip(data, 0.1, None))\n",
    "    trim_means_and_std = np.apply_along_axis(func1d=trim_mean_std, axis=0, arr=log_data, frac=frac)\n",
    "    means = trim_means_and_std[0,:].reshape(1,-1)\n",
    "    stds = trim_means_and_std[1,:].reshape(1,-1)\n",
    "    zeroed_data = np.subtract(log_data, means)\n",
    "    scaled_data = np.divide(zeroed_data, stds)\n",
    "    return scaled_data\n",
    "\n",
    "def ft_eng_and_scale(data):\n",
    "    nums = ['0%', '1%', '5%', '10%']\n",
    "    ratio_cols = ['1/0', '5/0', '10/0', '5/1', '10/1', '10/5']\n",
    "    ratios_df = create_ratios(data)\n",
    "    log_z_signal = trim_log_z_score(data[nums].values)\n",
    "    z_ratio = z_score(ratios_df.values)\n",
    "    X = np.concatenate((log_z_signal, z_ratio), axis=1)\n",
    "    X_df = pd.DataFrame(X, columns=(nums+ratio_cols))\n",
    "    X_df['AA'] = data['AA']\n",
    "    return X_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preprocessing data by protein\n",
    "IGPS_processed = ft_eng_and_scale(IGPS)\n",
    "PTP1B_processed = ft_eng_and_scale(PTP1B)\n",
    "your_protein_processed = ft_eng_and_scale(your_protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#separating user data by labeled and unlabeled\n",
    "unlabeled_processed = your_protein_processed.loc[your_protein_processed['AA']=='no_label']\n",
    "labeled_processed = your_protein_processed.loc[your_protein_processed['AA']!='no_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#formatting data for modelling and removing unmodeled amino acids\n",
    "model_data = pd.concat((IGPS_processed, PTP1B_processed, labeled_processed), axis=0)\n",
    "X = model_data.drop(columns=['AA']).values\n",
    "y = model_data['AA']\n",
    "\n",
    "def create_filter(AA_excluded, y, reverse=False):\n",
    "    all_labels = ['L','A', 'I', 'V', 'D', 'E', 'Q', 'S', 'T', 'F', 'G', 'H', 'R', 'K', 'C', 'N', 'M', 'W', 'Y' ]\n",
    "    labels = [x for x in all_labels if x not in AA_excluded]\n",
    "    my_filter = [True if aa not in AA_excluded else False for aa in y]\n",
    "    if reverse == True:\n",
    "        reverse_filter = [True if aa in AA_excluded else False for aa in y]\n",
    "        return my_filter, labels, reverse_filter\n",
    "    else:\n",
    "        return my_filter, labels\n",
    "    \n",
    "AA_excluded = ['W', 'Y', 'C']\n",
    "my_filter, labels, reverse_filter = create_filter(AA_excluded, y, reverse=True)\n",
    "X_filtered = X[my_filter, :]\n",
    "y_filtered = y[my_filter]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll use cross-validation to tune parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility function to report best scores\n",
    "def report(results, n_top=3):\n",
    "    all_params = []\n",
    "    for i in range(1, n_top + 1):\n",
    "        candidates = np.flatnonzero(results['rank_test_score'] == i)\n",
    "        for candidate in candidates:\n",
    "            print(\"Model with rank: {0}\".format(i))\n",
    "            print(\"Mean validation score: {0:.3f} (std: {1:.3f})\".format(\n",
    "                  results['mean_test_score'][candidate],\n",
    "                  results['std_test_score'][candidate]))\n",
    "            print(\"Parameters: {0}\".format(results['params'][candidate]))\n",
    "            print(\"\")\n",
    "            all_params.append(results['params'][candidate])\n",
    "    return all_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomizedSearchCV took 36.19 seconds for 25 candidates parameter settings.\n",
      "Model with rank: 1\n",
      "Mean validation score: 0.732 (std: 0.240)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 9, 'min_samples_split': 3}\n",
      "\n",
      "Model with rank: 2\n",
      "Mean validation score: 0.729 (std: 0.230)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': 5, 'min_samples_split': 5}\n",
      "\n",
      "Model with rank: 3\n",
      "Mean validation score: 0.725 (std: 0.251)\n",
      "Parameters: {'bootstrap': True, 'criterion': 'gini', 'max_depth': None, 'max_features': 7, 'min_samples_split': 2}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "clf_init = RandomForestClassifier(n_estimators=150, random_state=0)\n",
    "# specify parameters and distributions to sample from\n",
    "param_dist = {\"max_depth\": [3, None],\n",
    "              \"max_features\": sp_randint(1, 10),\n",
    "              \"min_samples_split\": sp_randint(2, 10),\n",
    "              \"bootstrap\": [True, False],\n",
    "              \"criterion\": [\"gini\", \"entropy\"]}\n",
    "\n",
    "# run randomized search\n",
    "n_iter_search = 25\n",
    "random_search = RandomizedSearchCV(clf_init, param_distributions=param_dist,\n",
    "                                   n_iter=n_iter_search, cv=5, iid=False, random_state = 0)\n",
    "\n",
    "start = time()\n",
    "random_search.fit(X_filtered, y_filtered)\n",
    "print(\"RandomizedSearchCV took %.2f seconds for %d candidates\"\n",
    "      \" parameter settings.\" % ((time() - start), n_iter_search))\n",
    "all_params = report(random_search.cv_results_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#select parameters\n",
    "params = all_params[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0%</th>\n",
       "      <th>1%</th>\n",
       "      <th>5%</th>\n",
       "      <th>10%</th>\n",
       "      <th>bucket</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>44878.0</td>\n",
       "      <td>35399.39127</td>\n",
       "      <td>28197.90367</td>\n",
       "      <td>27808.87681</td>\n",
       "      <td>DEQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>45768.0</td>\n",
       "      <td>31829.72942</td>\n",
       "      <td>14369.01023</td>\n",
       "      <td>18841.69090</td>\n",
       "      <td>LAIVMH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>80528.0</td>\n",
       "      <td>59971.64002</td>\n",
       "      <td>50153.13583</td>\n",
       "      <td>33555.46352</td>\n",
       "      <td>STGRFN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>43642.0</td>\n",
       "      <td>36039.34709</td>\n",
       "      <td>27277.08781</td>\n",
       "      <td>27101.01449</td>\n",
       "      <td>DEQ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>98323.0</td>\n",
       "      <td>63613.22351</td>\n",
       "      <td>9940.21114</td>\n",
       "      <td>12906.80585</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0%           1%           5%          10%  bucket\n",
       "0  44878.0  35399.39127  28197.90367  27808.87681     DEQ\n",
       "1  45768.0  31829.72942  14369.01023  18841.69090  LAIVMH\n",
       "2  80528.0  59971.64002  50153.13583  33555.46352  STGRFN\n",
       "3  43642.0  36039.34709  27277.08781  27101.01449     DEQ\n",
       "4  98323.0  63613.22351   9940.21114  12906.80585       K"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=150, **params, random_state=0)\n",
    "clf.fit(X, y)\n",
    "unlabeled_preds = clf.predict(unlabeled_processed.drop(columns='AA').values)\n",
    "bucketed_preds = [condensed_dict[i] for i in unlabeled_preds]\n",
    "unlabeled_data = unlabeled_data.drop(columns=['AA'])\n",
    "unlabeled_data['bucket'] = bucketed_preds\n",
    "unlabeled_data.to_csv('output_data/retrained_output.csv')\n",
    "unlabeled_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the unlabeled data that you supplied has been labeled. It has been saved in the file 'retrained_output.csv'."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
